---
title: "3.5 Modeling : Logistic Regression"
author: "Himanshu"
date: "April 10, 2019"
output: html_document
---
```{r}
library(dplyr)
library(caret)
library(lubridate)
library(stringr)
library(tidyr)
library(corrplot)
library(ggcorrplot)
library(leaps)
library(MASS)
library(ggplot2)
library(standardize)
library(Amelia)
```

```{r}
df <- read.csv("TransfromedData_1.csv", header = TRUE)
summary(df)
table(df$YearBefore)
```

```{r}
vars_to_remove <- c("X.1", "X","YearBefore","addr_state", "issue_d", "earliest_cr_line", "GeoName")

df1 <- df[, ! names(df) %in% vars_to_remove, drop = F]
str(df1)
```

```{r}

df1$dti <- as.numeric(df1$dti)
table(df1$loan_status)

```

```{r}
# We'll do stratified sampling to split our data into training and test sets

targetVar <- 'loan_status'
inTrain <- createDataPartition(y = df1[,targetVar], list = FALSE, p = .8)
train <- df1[inTrain,]
test <- df1[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(df1))
names(df1)
```

```{r}
xVars <- c("loan_amnt", "term", "int_rate", "installment", "grade",
           "home_ownership", "annual_inc", "verification_status", "purpose",
           "dti", "open_acc", "pub_rec", "total_acc", "initial_list_status", 
           "Compensation.of.employees", "Gross.operating.surplus", "Per.capita.real.GDP.by.state", 
           "Quantity.indexes.for.real.GDP.by.state", "Real.GDP.by.state", "Subsidies", 
           "Taxes.on.production.and.imports", "regions" )
```

```{r}
# Formula Function

createModelFormula <- function(targetVar, xVars, includeIntercept = TRUE){
  if(includeIntercept){
    modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ ')))
  } else {
    modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ '), -1))
  }
  return(modelForm)
}


```

```{r}
# Building model with all variables
modelForm <- createModelFormula(targetVar, xVars, includeIntercept = F)

model <- glm(modelForm,family=binomial(link='logit'),data=train)

summary(model)

```
```{r}
predictors(model)
```

```{r}
varImp(model)

```

```{r}
anova(model, test="Chisq")
```
```{r}
# testing model on test data set

fitted.results <- predict(model
                          ,newdata = test[,xVars]
                          # Specifying response means we want the probabilities
                          ,type='response')
hist(fitted.results)

test[,'fitted.results'] <- fitted.results
```

```{r}
# We output the probabilities, but we want to turn the probabilities into
# a classification of survived or not. .5 is a reasonable starting cutoff.

default.pred <- ifelse(fitted.results > 0.5,"Not Defaulted","Defaulted")
default.pred <- as.factor(default.pred)

class(default.pred)
class(test[,targetVar])

table(default.pred)
table(test[,targetVar])


```
```{r}
# Let's use a confusion matrix to evaluate how good our results are
confusion <- confusionMatrix(default.pred, test[,targetVar])                             
confusion
```


```{r}
Model1 <- stepAIC(model, direction = "forward")
```

```{r}
Model2 <- stepAIC(model, direction = "backward")

```
```{r}
Model_Step <- stepAIC(model, direction = "both", )
```

```{r}
anova(model, Model_Step)
```


```{r}
# Only three variable model 

xVars3 <- c("Subsidies", "Compensation.of.employees", "open_acc")

modelForm <- createModelFormula(targetVar, xVars3)

model_final2 <- glm(modelForm,family=binomial(link='logit'),data=train)

summary(model_final2)
```

```{r}
fitted.results <- predict(model_final2
                          ,newdata = test[,xVars3]
                          # Specifying response means we want the probabilities
                          ,type='response')

test[,'fitted.results'] <- fitted.results

# We output the probabilities, but we want to turn the probabilities into
# a classification of survived or not. .5 is a reasonable starting cutoff.

default.pred <- ifelse(fitted.results > 0.5,"Not Defaulted","Defaulted")
default.pred <- as.factor(default.pred)

class(default.pred)
class(test[,targetVar])

table(default.pred)
table(test[,targetVar])

# Let's use a confusion matrix to evaluate how good our results are
confusion <- confusionMatrix(default.pred, test[,targetVar])                             
confusion
```
```{r}
# removing the above three varibles and building final model
# We'll do stratified sampling to split our data into training and test sets

targetVar <- 'loan_status'
inTrain1 <- createDataPartition(y = df1[,targetVar], list = FALSE, p = .8)
train1 <- df1[inTrain,]
test1 <- df1[-inTrain,]
stopifnot(nrow(train1) + nrow(test1) == nrow(df1))

xVars1 <- c("loan_amnt", "term", "int_rate", "installment", "grade",
           "home_ownership", "annual_inc", "verification_status", "purpose",
           "dti", "pub_rec", "total_acc", "initial_list_status", 
           "Gross.operating.surplus", "Per.capita.real.GDP.by.state", 
           "Quantity.indexes.for.real.GDP.by.state", "Real.GDP.by.state", 
           "Taxes.on.production.and.imports", "regions" )
# Formula Function

createModelFormula <- function(targetVar, xVars1, includeIntercept = TRUE){
  if(includeIntercept){
    modelForm <- as.formula(paste(targetVar, "~", paste(xVars1, collapse = '+ ')))
  } else {
    modelForm <- as.formula(paste(targetVar, "~", paste(xVars1, collapse = '+ '), -1))
  }
  return(modelForm)
}

# Building model with all variables
modelForm <- createModelFormula(targetVar, xVars1, includeIntercept = F)

model_final <- glm(modelForm,family=binomial(link='logit'),data=train1)

summary(model_final)
```

```{r}
# testing model on test data set

fitted.results <- predict(model_final
                          ,newdata = test1[,xVars1]
                          # Specifying response means we want the probabilities
                          ,type='response')
hist(fitted.results)

test1[,'fitted.results'] <- fitted.results

# We output the probabilities, but we want to turn the probabilities into
# a classification of survived or not. .5 is a reasonable starting cutoff.

default.pred <- ifelse(fitted.results > 0.5,"Not Defaulted","Defaulted")
default.pred <- as.factor(default.pred)

class(default.pred)
class(test1[,targetVar])

table(default.pred)
table(test1[,targetVar])

# Let's use a confusion matrix to evaluate how good our results are
confusion <- confusionMatrix(default.pred, test1[,targetVar])                             
confusion
```
```{r}
# Our first model with all variables was better
```


```{r}
# Let's look at the ROC curve
library(ROCR)
pr <- prediction(fitted.results, test$loan_status)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```

```{r}
# Let's look at the precision recall curves
# install.packages('DMwR')
library('DMwR')
PRcurve(preds = fitted.results, trues = test$loan_status)

# Let's take a look at the deviance
llcomponents <- function(y, predicted.y){
  return(y*log(predicted.y) + (1-y)*log(1-predicted.y))
}
y <- train[,targetVar]
predicted.y <- predict(model
                       ,newdata = train[,xVars]
                       # Specifying response means we want the probabilities
                       ,type='response')

deviance <- sign(as.numeric(y) - predicted.y)*sqrt(-2*llcomponents(as.numeric(y), predicted.y))

summary(deviance)
```

```{r}
# Pseudo-R**2
mod <- glm(loan_status~loan_amnt+term+int_rate+installment+grade+
           home_ownership+annual_inc+verification_status+purpose+
           dti+open_acc+pub_rec+total_acc+initial_list_status+ 
           Compensation.of.employees+Gross.operating.surplus+Per.capita.real.GDP.by.state+ 
           Quantity.indexes.for.real.GDP.by.state+Real.GDP.by.state+Subsidies+ 
           Taxes.on.production.and.imports+regions , family="binomial", data = train)
nullmod <- glm(loan_status~1, family="binomial", data = train)
1-logLik(mod)/logLik(nullmod)

```



```{r}
library(earth)
marsModel <- earth(loan_status ~ ., data=df1) # build model
ev <- evimp (marsModel)
ev
```
```{r}
model_feature <- glm(loan_status~int_rate+Quantity.indexes.for.real.GDP.by.state+annual_inc+
                       initial_list_status +Taxes.on.production.and.imports,
                     family=binomial(link='logit'),data=train)

features <- c("int_rate","Quantity.indexes.for.real.GDP.by.state","annual_inc",
                       "initial_list_status","Taxes.on.production.and.imports")
```

```{r}
# testing model on test data set

fitted.results <- predict(model_feature
                          ,newdata = test[,features]
                          # Specifying response means we want the probabilities
                          ,type='response')
hist(fitted.results)

test[,'fitted.results'] <- fitted.results

# We output the probabilities, but we want to turn the probabilities into
# a classification of survived or not. .5 is a reasonable starting cutoff.

default.pred <- ifelse(fitted.results > 0.5,"Not Defaulted","Defaulted")
default.pred <- as.factor(default.pred)

class(default.pred)
class(test[,targetVar])

table(default.pred)
table(test[,targetVar])

# Let's use a confusion matrix to evaluate how good our results are
confusion <- confusionMatrix(default.pred, test[,targetVar])                             
confusion
```
```{r}
#We found that No Information rate is higher than any of our any model
```


```{r}

# ensure results are repeatable
set.seed(7)
# load the library
library(mlbench)
library(caret)
# load the dataset
df1
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(loan_status~., data=df1, method="lvq", preProcess="scale", trControl=control)

# estimate variable importance
importance <- varImp(model, scale=FALSE)

# summarize importance
print(importance)
# plot importance
plot(importance)

```

















