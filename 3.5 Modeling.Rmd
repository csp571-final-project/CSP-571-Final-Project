---
title: "3.5 Modeling : Logistic Regression"
author: "Himanshu"
date: "April 10, 2019"
output: html_document
---
```{r}
library(dplyr)
library(caret)
library(lubridate)
library(stringr)
library(tidyr)
library(corrplot)
library(ggcorrplot)
library(leaps)
library(MASS)
library(ggplot2)
library(standardize)
library(Amelia)
library(ROCR)
library(glmnet)
```

```{r}
train <- read.csv("TrainData.csv", header = TRUE)
test <- read.csv("TestData.csv", header = TRUE)
str(train)
str(test)

```

```{r}
vars_to_remove <- c("X.1", "X","pymnt_plan", "GeoName", "application_type")

train <- train[, ! names(train) %in% vars_to_remove, drop = F]
str(train)

test <- test[, ! names(test) %in% vars_to_remove, drop = F]
str(test)
```



```{r}
xVars <- c("loan_amnt", "term", "int_rate", "installment", "grade",
           "home_ownership", "annual_inc", "verification_status","purpose",
           "dti", "open_acc", "pub_rec", "total_acc", "initial_list_status", 
           "Compensation.of.employees", "Gross.operating.surplus", "Per.capita.real.GDP.by.state", 
           "Quantity.indexes.for.real.GDP.by.state", "Real.GDP.by.state", "Subsidies", 
           "Taxes.on.production.and.imports", "regions", "month" )
```



```{r}
# Formula Function

createModelFormula <- function(targetVar, xVars, includeIntercept = TRUE){
  if(includeIntercept){
    modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ ')))
  } else {
    modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ '), -1))
  }
  return(modelForm)
}


```

```{r}
# Building model with all variables
modelForm <- createModelFormula(targetVar, xVars, includeIntercept = T)

full_model <- glm(modelForm,family=binomial(link='logit'),data=train)

summary(full_model)

```

```{r}
full_model_Pred <- 
  predict.glm(object = full_model, newdata = test, type = "response")
model_pred_t<- unname(ifelse(full_model_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default)) 

# Let's look at the ROC curve
pr <- prediction(full_model_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

```

```{r}
varImp<- varImp(full_model)
varImp

```
```{r}
# Building model for VarImp variables

test_model <- glm(default~int_rate+grade+annual_inc+purpose+pub_rec+initial_list_status+Quantity.indexes.for.real.GDP.by.state+Real.GDP.by.state+month+Taxes.on.production.and.imports-1,family=binomial(link='logit'), data=train, na.action = na.exclude)

x <- c("int_rate","grade","annual_inc","purpose","pub_rec","initial_list_status","Quantity.indexes.for.real.GDP.by.state","Real.GDP.by.state","month", "Taxes.on.production.and.imports")

test_model_Pred <- 
  predict.glm(object = test_model, newdata = test, type = "response")
model_pred_t<- unname(ifelse(test_model_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default))

# Let's look at the ROC curve
pr <- prediction(test_model_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc


```

```{r}
# Building model with No variables
model_Null <- glm(default ~ 1,family=binomial(link='logit'),data=train)
summary(model_Null)
```

```{r}
# Forward model

Model_forward <- stepAIC(model_Null, direction = "forward", scope=list(upper=full_model,lower=model_Null))
model1 <- glm(default ~ loan_amnt+ Subsidies+Real.GDP.by.state+ Compensation.of.employees, family=binomial(link='logit'),data=train)
summary(model1)
x <- c("loan_amnt", "Subsidies","Real.GDP.by.state", "Compensation.of.employees")

model1_Pred <- 
  predict.glm(object = model1, newdata = test, type = "response")
model_pred_t<- unname(ifelse(model1_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t
str(model_pred_t)
str(test$default)
str(test$model_pred_t)

with(test, table(test$model_pred_t, default))

#confusionMatrix(test$model_pred_t, test$default)
hist(model1_Pred)


# Let's look at the ROC curve
pr <- prediction(model1_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc


#this looks really bad model
```

```{r}
Model_backward <- stepAIC(full_model, direction = "backward")

model2 <- glm(default ~ loan_amnt+Subsidies+Real.GDP.by.state+Compensation.of.employees,
              family=binomial(link='logit'),data=train)
summary(model2)
x2 <- c( "loan_amnt",
           "Compensation.of.employees", 
           "Real.GDP.by.state", "Subsidies" 
            )

model2_Pred <- 
  predict.glm(object = model2, newdata = test, type = "response")
model_pred_t<- unname(ifelse(model2_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

with(test, table(test$model_pred_t, default))
#confusionMatrix(table(test$model_pred_t, test$default))
hist(model2_Pred)


# Let's look at the ROC curve
pr <- prediction(model2_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc


```

```{r}
Model_Step <- stepAIC(full_model, direction = "both" )
model3 <- glm(default ~ term+Per.capita.real.GDP.by.state, family=binomial(link='logit'),data=train_down)
summary(model3)
x3 <- c( "term",
           "Per.capita.real.GDP.by.state")

model3_Pred <- 
  predict.glm(object = model3, newdata = test, type = "response")
model_pred_t<- unname(ifelse(model3_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default))
hist(model3_Pred)

# Let's look at the ROC curve

pr <- prediction(model3_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```


```{r}
library(earth)
marsModel <- earth(default ~ ., data=train_down) # build model
ev <- evimp (marsModel)
ev
```
```{r}
model4 <- glm(default ~ int_rate+annual_inc+term+dti+purpose+loan_amnt+home_ownership, family=binomial(link='logit'), data=train)

summary(model4)

x3 <- c("int_rate","annual_inc","term", "dti","purpose","loan_amnt","home_ownership")

model4_Pred <- 
  predict.glm(object = model4, newdata = test, type = "response")
model_pred_t<- unname(ifelse(model3_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default))
hist(model4_Pred)
```

```{r}
# Let's look at the ROC curve
library(ROCR)
pr <- prediction(model4_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```

```{r}
# Primary data model 
xPrimary <- c("loan_amnt", "term", "int_rate", "installment", "grade",
           "home_ownership", "annual_inc", "verification_status", "purpose",
           "dti", "open_acc", "pub_rec", "total_acc", "initial_list_status", 
           "regions", "month" )

modelForm <- createModelFormula(targetVar, xPrimary, includeIntercept = T)

Primary_model <- glm(modelForm,family=binomial(link='logit'),data=train)

summary(Primary_model)

Primary_model_Pred <- 
  predict.glm(object = Primary_model, newdata = test, type = "response")
model_pred_t<- unname(ifelse(Primary_model_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default))
hist(Primary_model_Pred)

# Let's look at the ROC curve
pr <- prediction(Primary_model_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

```

```{r}
library(party)
cf1 <- cforest(default ~ . , data= train_down, control=cforest_unbiased(mtry=2,ntree=50))
cf1
```
```{r}
model5 <- glm(default ~ loan_amnt+ term+ int_rate+ installment+ grade+ home_ownership+ annual_inc+ verification_status+ pymnt_plan+ purpose+ dti+ open_acc+ pub_rec+ total_acc+ initial_list_status+ Compensation.of.employees+ Gross.operating.surplus+ Per.capita.real.GDP.by.state+ Quantity.indexes.for.real.GDP.by.state+ Real.GDP.by.state+ Subsidies+ Taxes.on.production.and.imports+ regions+ month , family=binomial(link='logit'), data=train)

summary(model5)

model5_Pred <- 
  predict.glm(object = model5, newdata = test, type = "response")
model_pred_t<- unname(ifelse(model5_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default))
hist(model5_Pred)
```
```{r}
#leaps (regression subset selection)
require(leaps)
require(MASS)
regsubsets.out <- regsubsets(default ~ loan_amnt+ term+ int_rate+ installment+ grade+ home_ownership+ annual_inc+ verification_status+ purpose+ dti+ open_acc+ pub_rec+ total_acc+ initial_list_status+ Compensation.of.employees+ Gross.operating.surplus+ Per.capita.real.GDP.by.state+ Quantity.indexes.for.real.GDP.by.state+ Real.GDP.by.state+ Subsidies+ Taxes.on.production.and.imports+ regions+ month, data=train, nbest= 1, method= "exhaustive")
summary(regsubsets.out)

#Best model at each variable number
summary.out <- summary(regsubsets.out)
as.data.frame(summary.out$outmat)
```
```{r}
## Adjusted R2
plot(regsubsets.out, scale = "adjr2", main = "Adjusted R^2")
```


```{r}
library(car)
layout(matrix(1:1, ncol = 1))
## Adjusted R2

res.legend <-
    subsets(regsubsets.out, statistic="adjr2", legend = FALSE, min.size = 5, main = "Adjusted R^2")
## Mallow Cp
## Mallow Cp is used to decide on the number of predictors to include. 
res.legend <-
    subsets(regsubsets.out, statistic="cp", legend = FALSE, min.size = 5, main = "Mallow Cp")
abline(a = 1, b = 1, lty = 2)
res.legend
```
```{r}
## See which model has the highest adjusted R2
which.max(summary.out$adjr2)
```

```{r}
summary.out$which[8,]
```
```{r}
#building model with our best variables
final_model <- glm(default ~ term+home_ownership+purpose+total_acc+int_rate+annual_inc+ dti+regions
                     , family=binomial(link='logit'), data=train)

summary(final_model)

final_model_Pred <- 
  predict.glm(object = final_model, newdata = test, type = "response")
model_pred_t<- unname(ifelse(final_model_Pred > .5, TRUE, FALSE))
test[,'model_pred_t'] <- model_pred_t

confusionMatrix(table(test$model_pred_t, test$default))
hist(final_model_Pred)

# Pseudo-R**2
nullmod <- glm(default~1, family="binomial", data = train)
1-logLik(final_model)/logLik(nullmod)

pr <- prediction(final_model_Pred, test$default)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```

```{r}
write.csv(test, file = "LogisticTest.csv" )
```













